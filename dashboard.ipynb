{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1yt3JtqpATHG3ANUEnbSIh8ST19bLgoF1",
      "authorship_tag": "ABX9TyP/A/AmxEPMT2qsYQluZQO4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/izzamokhtar/urbanrent/blob/main/dashboard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AjknRcb6tP04",
        "outputId": "7f2a1ffe-73cd-46f7-a1f6-777f569009c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.41.1-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.2-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (11.0.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.25.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.41.1-py2.py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.2-py3-none-any.whl (22 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pyngrok, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 pyngrok-7.2.2 streamlit-1.41.1 watchdog-6.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "!ngrok authtoken 2q3MywynEFtR5FkvEPDc4HIEvHz_ky4NtHhoZD952M4HGaNK # Replace <your_auth_token> with your actual token\n",
        "!streamlit run app.py &> /dev/null &\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"Streamlit app is live at: {public_url}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyFwrnJYtpQg",
        "outputId": "39a99f7f-bca9-4e0a-c854-b53c9cc345de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "Streamlit app is live at: NgrokTunnel: \"https://e1c4-35-190-150-132.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill -f ngrok"
      ],
      "metadata": {
        "id": "JLPQyPvk2Ccp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#yang ni latest\n",
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from warnings import filterwarnings\n",
        "\n",
        "st.set_page_config(page_title=\"Rent Price Prediction\", page_icon=\":heavy_dollar_sign:\")\n",
        "filterwarnings('ignore', category=FutureWarning)\n",
        "\n",
        "# Sidebar for navigation\n",
        "#page = st.sidebar.radio(\"Navigate\", [\"Rental Prediction\", \"Interactive Graphs\", \"Data Analysis\"])\n",
        "# Sidebar navigation with icons\n",
        "page = st.sidebar.radio(\n",
        "    \"\",\n",
        "    [\n",
        "        \"💲 Rent Prediction\",\n",
        "        \"📊 Interactive Graphs\",\n",
        "        \"📈 Map Visualisation\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "if page == \"💲 Rent Prediction\":\n",
        "    st.empty()\n",
        "    exec(open(\"rental.py\").read())\n",
        "\n",
        "if page == \"📊 Interactive Graphs\":\n",
        "    st.empty()\n",
        "    exec(open(\"dashboard.py\").read())\n",
        "\n",
        "if page == \"📈 Map Visualisation\":\n",
        "    st.empty()\n",
        "    exec(open(\"visual.py\").read())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeJahdCKTVEF",
        "outputId": "7748f2a9-a722-4beb-9d24-38bf45ad6a95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#latest\n",
        "%%writefile rental.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from warnings import filterwarnings\n",
        "\n",
        "# Load the best model\n",
        "best_model_pipeline = joblib.load(\"/content/drive/MyDrive/FYP B IZZA/best_model_pipeline.pkl\")\n",
        "linear_model_pipeline = joblib.load('/content/drive/MyDrive/FYP B IZZA/linear_regression_pipeline.pkl')\n",
        "#random_forest_pipeline = joblib.load('/content/drive/MyDrive/FYP B IZZA/random_forest_pipeline.pkl')\n",
        "gradient_boosting_pipeline = joblib.load('/content/drive/MyDrive/FYP B IZZA/gradient_boosting_pipeline.pkl')\n",
        "\n",
        "# Load the best model's name\n",
        "with open(\"/content/drive/MyDrive/FYP B IZZA/best_model_name.txt\", \"r\") as f:\n",
        "    best_model_name = f.read()\n",
        "\n",
        "# Extract categories for user input from the best model's preprocessor\n",
        "preprocessor = best_model_pipeline.named_steps['preprocessor']\n",
        "onehot_encoder = preprocessor.named_transformers_['cat'].named_steps['onehot']\n",
        "location_categories = onehot_encoder.categories_[0]\n",
        "property_type_categories = onehot_encoder.categories_[1]\n",
        "\n",
        "st.title(\"Rental Price Prediction\")\n",
        "st.write(f\"Predict monthly rental prices using the most accurate model: **{best_model_name}**\")\n",
        "\n",
        "# User input\n",
        "location = st.selectbox(\"Location\", location_categories)\n",
        "property_type = st.selectbox(\"Property Type\", property_type_categories)\n",
        "rooms = st.number_input(\"Number of Rooms\", value=2)\n",
        "bathrooms = st.number_input(\"Number of Bathrooms\", value=1)\n",
        "parking = st.number_input(\"Number of Parking Spaces\", value=1)\n",
        "\n",
        "# Combine user inputs into a DataFrame\n",
        "user_input = pd.DataFrame({\n",
        "    'location': [location],\n",
        "    'property_type': [property_type],\n",
        "    'rooms': [rooms],\n",
        "    'bathroom': [bathrooms],\n",
        "    'parking': [parking]\n",
        "})\n",
        "\n",
        "# Predict with the best model\n",
        "if st.button(\"Predict\"):\n",
        "    prediction = best_model_pipeline.predict(user_input)[0]\n",
        "    st.write(f\"Predicted Rent using {best_model_name}: RM{prediction:.2f}\")\n",
        "    linear_prediction = linear_model_pipeline.predict(user_input)[0]\n",
        "    gradient_boosting_prediction = gradient_boosting_pipeline.predict(user_input)[0]\n",
        "\n",
        "    # Plot predictions\n",
        "    algorithms = ['Linear Regression', 'Random Forest', 'Gradient Boosting']\n",
        "    predictions = [linear_prediction, prediction, gradient_boosting_prediction]\n",
        "\n",
        "    # Create a bar chart\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.bar(algorithms, predictions, color=['blue', 'green', 'orange'])\n",
        "    ax.set_ylabel('Predicted Rental Price (RM)')\n",
        "    ax.set_title('Comparison of Predicted Prices')\n",
        "    st.pyplot(fig)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xx9Kte2vFeDm",
        "outputId": "1faee955-70ad-4556-a936-eda669f980dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing rental.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#latesttt\n",
        "%%writefile dashboard.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import joblib\n",
        "import numpy as np\n",
        "from itertools import product\n",
        "\n",
        "st.title(\"Rent Pricing at Kuala Lumpur and Selangor\")\n",
        "\n",
        "# Load the dataset\n",
        "@st.cache_data\n",
        "def load_data():\n",
        "    df = pd.read_csv('/content/drive/MyDrive/FYP B IZZA/mudah-apartment-kl-selangor_cleaned.csv')\n",
        "    df.columns = df.columns.str.strip().str.lower()\n",
        "    df['monthly_rent'] = df['monthly_rent'].str.replace('RM', '').str.replace('per month', '').str.replace(' ', '')\n",
        "    df['monthly_rent'] = pd.to_numeric(df['monthly_rent'], errors='coerce')\n",
        "    df = df.dropna(subset=['monthly_rent'])\n",
        "    return df\n",
        "\n",
        "df = load_data()\n",
        "\n",
        "# Load the trained model pipeline\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    model = joblib.load('/content/drive/MyDrive/FYP B IZZA/best_model_pipeline.pkl')  # Your trained model\n",
        "    return model\n",
        "\n",
        "model = load_model()\n",
        "\n",
        "# Sidebar for user input (only Location and Property Type)\n",
        "st.sidebar.title('Interactive Graphs')\n",
        "st.sidebar.header('Graph Parameters')\n",
        "\n",
        "# User selects the parameters for filtering data\n",
        "selected_locations = st.sidebar.multiselect('Select Locations', df['location'].unique())\n",
        "selected_property_types = st.sidebar.multiselect('Select Property Types', df['property_type'].unique())\n",
        "\n",
        "# Ensure there is at least one location and one property type selected\n",
        "if not selected_locations or not selected_property_types:\n",
        "    st.warning(\"Please select at least one location and one property type.\")\n",
        "    st.stop()\n",
        "\n",
        "# Generate all combinations of selected locations and property types\n",
        "combinations = list(product(selected_locations, selected_property_types))\n",
        "\n",
        "# Prepare input for the model\n",
        "model_input = pd.DataFrame(combinations, columns=['location', 'property_type'])\n",
        "\n",
        "# Add dummy values for other features (rooms, bathroom, parking)\n",
        "model_input['rooms'] = 2  # Default room value\n",
        "model_input['bathroom'] = 1  # Default bathroom value\n",
        "model_input['parking'] = 1  # Default parking value\n",
        "\n",
        "# Apply the same transformations as the model expects (e.g., one-hot encoding, scaling)\n",
        "# Assuming the model uses a ColumnTransformer for preprocessing:\n",
        "try:\n",
        "    transformed_input = model.transform(model_input)\n",
        "except AttributeError:\n",
        "    # Handle the case where the model is not a pipeline and does not need transformation\n",
        "    transformed_input = model_input  # You may need to manually apply transformations here\n",
        "\n",
        "# Get predictions for rent prices from the model\n",
        "predicted_prices = model.predict(transformed_input)\n",
        "\n",
        "# Prepare the data for the graph (create a DataFrame with predicted prices)\n",
        "graph_data = pd.DataFrame({\n",
        "    'location': model_input['location'],\n",
        "    'property_type': model_input['property_type'],\n",
        "    'predicted_rent': predicted_prices\n",
        "})\n",
        "\n",
        "# Round the predicted prices to 2 decimal points\n",
        "graph_data['predicted_rent'] = graph_data['predicted_rent'].round(2)\n",
        "\n",
        "# Visualization Columns\n",
        "col1, col2 = st.columns(2)\n",
        "\n",
        "# Graph 1: Average Price by Location (based on model prediction)\n",
        "avg_price_location = graph_data.groupby('location')['predicted_rent'].mean().reset_index()\n",
        "avg_price_location['predicted_rent'] = avg_price_location['predicted_rent'].round(2)\n",
        "fig1 = px.bar(avg_price_location, x='location', y='predicted_rent', color='location', title=\"Average Price by Location\")\n",
        "\n",
        "# Increase the graph size and rename axis labels\n",
        "fig1.update_layout(\n",
        "    title_font_size=20,  # Adjust title font size\n",
        "    xaxis_title='Location',  # Rename the x-axis\n",
        "    yaxis_title='Price (RM)',  # Rename the y-axis\n",
        "    xaxis_title_font_size=14,  # Adjust x-axis title font size\n",
        "    yaxis_title_font_size=14,  # Adjust y-axis title font size\n",
        "    showlegend=True,  # Show legend if necessary\n",
        ")\n",
        "\n",
        "col1.plotly_chart(fig1, use_container_width=True)\n",
        "\n",
        "# Graph 2: Average Price by Property Type (based on model prediction)\n",
        "avg_price_property = graph_data.groupby('property_type')['predicted_rent'].mean().reset_index()\n",
        "avg_price_property['predicted_rent'] = avg_price_property['predicted_rent'].round(2)\n",
        "fig2 = px.bar(avg_price_property, x='property_type', y='predicted_rent', color='property_type', title=\"Average Price by Property Type\")\n",
        "\n",
        "# Increase the graph size and rename axis labels\n",
        "fig2.update_layout(\n",
        "    title_font_size=20,  # Adjust title font size\n",
        "    xaxis_title='Property Type',  # Rename the x-axis\n",
        "    yaxis_title='Price (RM)',  # Rename the y-axis\n",
        "    xaxis_title_font_size=14,  # Adjust x-axis title font size\n",
        "    yaxis_title_font_size=14,  # Adjust y-axis title font size\n",
        "    showlegend=True,  # Show legend if necessary\n",
        ")\n",
        "\n",
        "col2.plotly_chart(fig2, use_container_width=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gYUBfDob1l9",
        "outputId": "bc05cde8-6883-496b-fc14-25d77db36ade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting dashboard.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install geopy"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAWYT13KoVmZ",
        "outputId": "57a1f2b6-9a63-40fa-af58-97e461fc0398"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: geopy in /usr/local/lib/python3.10/dist-packages (2.4.1)\n",
            "Requirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.10/dist-packages (from geopy) (2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile visual.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import folium\n",
        "from geopy.geocoders import Nominatim\n",
        "from folium.plugins import MarkerCluster\n",
        "\n",
        "# Load your dataset\n",
        "@st.cache_data\n",
        "def load_data():\n",
        "    # Replace with your actual dataset path\n",
        "    df = pd.read_csv('/content/drive/MyDrive/FYP B IZZA/mudah-apartment-kl-selangor_cleaned.csv')\n",
        "\n",
        "    # Clean dataset columns (normalize column names)\n",
        "    df.columns = df.columns.str.strip().str.lower()\n",
        "\n",
        "    # Clean 'monthly_rent' column (remove RM and convert to numeric)\n",
        "    df['monthly_rent'] = (\n",
        "        df['monthly_rent']\n",
        "        .str.replace('RM', '', regex=False)\n",
        "        .str.replace('per month', '', regex=False)\n",
        "        .str.replace(' ', '', regex=False)\n",
        "        .apply(pd.to_numeric, errors='coerce')\n",
        "    )\n",
        "\n",
        "    # Drop rows with NaN values in important columns\n",
        "    df = df.dropna(subset=['monthly_rent', 'prop_name', 'location', 'property_type'])\n",
        "\n",
        "    return df\n",
        "\n",
        "df = load_data()\n",
        "\n",
        "# Geocoding function with user-agent\n",
        "def geocode_location(location_name):\n",
        "    geolocator = Nominatim(user_agent=\"my_rent_dashboard (213061@student.upm.edu.my)\")  # Change this to your app name and contact\n",
        "    location = geolocator.geocode(location_name)\n",
        "    if location:\n",
        "        return location.latitude, location.longitude\n",
        "    else:\n",
        "        return None, None\n",
        "\n",
        "# Sidebar for user input\n",
        "st.sidebar.title('Interactive Map for Locations')\n",
        "st.sidebar.header('Select Location and Property Type')\n",
        "\n",
        "# Get unique locations and property types from the dataset\n",
        "locations = df['location'].unique()\n",
        "property_types = df['property_type'].unique()\n",
        "\n",
        "# User selects the parameters for filtering data\n",
        "selected_locations = st.sidebar.multiselect('Select Locations', locations)\n",
        "selected_property_types = st.sidebar.multiselect('Select Property Types', property_types)\n",
        "\n",
        "# Filter the dataset based on the selected location and property type\n",
        "filtered_data = df[\n",
        "    (df['location'].isin(selected_locations)) &\n",
        "    (df['property_type'].isin(selected_property_types))\n",
        "]\n",
        "\n",
        "# Check if any data is available after filtering\n",
        "if filtered_data.empty:\n",
        "    st.warning(\"No data available for the selected filters.\")\n",
        "else:\n",
        "    # Initialize map centered at a default location (e.g., Kuala Lumpur)\n",
        "    m = folium.Map(location=[3.139, 101.6869], zoom_start=12)\n",
        "    marker_cluster = MarkerCluster().add_to(m)\n",
        "\n",
        "    # Iterate through the filtered data to add markers for each property\n",
        "    for index, row in filtered_data.iterrows():\n",
        "        prop_name = row['prop_name']\n",
        "        location_name = row['location']\n",
        "\n",
        "        # Geocode location name to get latitude and longitude\n",
        "        lat, lon = geocode_location(location_name)\n",
        "\n",
        "        if lat and lon:\n",
        "            folium.Marker(\n",
        "                location=[lat, lon],\n",
        "                popup=f\"Property: {prop_name}<br>Location: {location_name}<br>Type: {row['property_type']}<br>Price: RM {row['monthly_rent']}\",\n",
        "            ).add_to(marker_cluster)\n",
        "\n",
        "    # Display the map\n",
        "    st.write(\"### Property Locations Map\")\n",
        "    folium_static(m)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEnvPi911UP2",
        "outputId": "f68474b4-e102-4499-f9b3-2b9826eb7f3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting visual.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile visual.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import pickle\n",
        "from geopy.geocoders import Nominatim\n",
        "import joblib\n",
        "\n",
        "st.title(\"Interactive Map Visualization\")\n",
        "\n",
        "# 1. Load the trained model\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    with open('/content/drive/MyDrive/FYP B IZZA/best_model_pipeline.pkl', 'rb') as file:  # Update path to your trained model\n",
        "        model = pickle.load(file)\n",
        "    return model\n",
        "\n",
        "model = load_model()\n",
        "\n",
        "# 2. Assuming your original dataset (the one you used for training the model) is available\n",
        "# You can load the original dataset to extract unique locations and property types\n",
        "\n",
        "@st.cache_data\n",
        "def load_training_data():\n",
        "    # Load the dataset used to train the model\n",
        "    df = pd.read_csv('/content/drive/MyDrive/FYP B IZZA/mudah-apartment-kl-selangor_cleaned.csv')  # Update with your dataset path\n",
        "    return df\n",
        "\n",
        "df = load_training_data()\n",
        "\n",
        "# 3. Extract unique locations and property types from the training data (not hardcoded)\n",
        "locations = df['location'].unique().tolist()\n",
        "property_types = df['property_type'].unique().tolist()\n",
        "\n",
        "# 4. Sidebar for User Input\n",
        "st.sidebar.header(\"Select Map Parameters\")\n",
        "selected_location = st.sidebar.selectbox(\"Select Location\", locations)\n",
        "selected_property_type = st.sidebar.selectbox(\"Select Property Type\", property_types)\n",
        "\n",
        "# 5. Geocode the selected location to get latitude and longitude\n",
        "@st.cache_data\n",
        "def geocode_location(location_name):\n",
        "    geolocator = Nominatim(user_agent=\"geoapi\")\n",
        "    try:\n",
        "        location = geolocator.geocode(location_name)\n",
        "        if location:\n",
        "            return location.latitude, location.longitude\n",
        "        else:\n",
        "            return None, None\n",
        "    except:\n",
        "        return None, None\n",
        "\n",
        "latitude, longitude = geocode_location(selected_location)\n",
        "\n",
        "# 6. Display Interactive Map\n",
        "if latitude and longitude:\n",
        "    st.header(\"Map Visualization\")\n",
        "    # Create a DataFrame for Plotly\n",
        "    map_data = pd.DataFrame({\n",
        "        \"location\": [selected_location],\n",
        "        \"property_type\": [selected_property_type],\n",
        "        \"latitude\": [latitude],\n",
        "        \"longitude\": [longitude]\n",
        "    })\n",
        "\n",
        "    # Interactive Map using Plotly\n",
        "    fig = px.scatter_mapbox(\n",
        "        map_data,\n",
        "        lat=\"latitude\",\n",
        "        lon=\"longitude\",\n",
        "        hover_name=\"location\",\n",
        "        hover_data=[\"property_type\"],\n",
        "        color_discrete_sequence=[\"blue\"],\n",
        "        zoom=12,\n",
        "        height=700,\n",
        "        title=\"Selected Location on Map\"\n",
        "    )\n",
        "    fig.update_layout(mapbox_style=\"open-street-map\")\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "else:\n",
        "    st.warning(\"Could not find latitude and longitude for the selected location. Please try another location.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MVQu1IFtsxw",
        "outputId": "26a98e03-d89d-44fb-95c6-dafd1c58a9f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting visual.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile visual.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from geopy.geocoders import Nominatim\n",
        "import time\n",
        "\n",
        "st.title(\"Location Map Visualization Without Latitude/Longitude\")\n",
        "\n",
        "# 1. Load Dataset\n",
        "@st.cache_data\n",
        "def load_data():\n",
        "    df = pd.read_csv('/content/drive/MyDrive/FYP B IZZA/mudah-apartment-kl-selangor_cleaned.csv')  # Replace with your dataset\n",
        "    df.columns = df.columns.str.strip().str.lower()\n",
        "    return df\n",
        "\n",
        "df = load_data()\n",
        "\n",
        "# 2. Sidebar inputs for filtering\n",
        "st.sidebar.header(\"Graph Parameters\")\n",
        "selected_property_type = st.sidebar.selectbox(\"Select Property Type\", df['property_type'].unique())\n",
        "\n",
        "# 3. Filter dataset based on user input\n",
        "filtered_data = df[df['property_type'] == selected_property_type]\n",
        "\n",
        "# 4. Geocoding Function (Get latitude & longitude for locations)\n",
        "@st.cache_data\n",
        "def geocode_location(location_names):\n",
        "    geolocator = Nominatim(user_agent=\"geoapi\")  # Initialize geolocator\n",
        "    lat_lon_data = []\n",
        "    for location in location_names:\n",
        "        try:\n",
        "            location_info = geolocator.geocode(location)  # Fetch location details\n",
        "            if location_info:\n",
        "                lat_lon_data.append((location, location_info.latitude, location_info.longitude))\n",
        "            else:\n",
        "                lat_lon_data.append((location, None, None))  # Append None if not found\n",
        "            time.sleep(1)  # To respect rate limits\n",
        "        except Exception as e:\n",
        "            lat_lon_data.append((location, None, None))\n",
        "    return pd.DataFrame(lat_lon_data, columns=[\"location\", \"latitude\", \"longitude\"])\n",
        "\n",
        "# 5. Get Latitude/Longitude for Unique Locations\n",
        "unique_locations = filtered_data['location'].unique()\n",
        "location_data = geocode_location(unique_locations)\n",
        "\n",
        "# 6. Merge Latitude/Longitude Back to Dataset\n",
        "merged_data = pd.merge(filtered_data, location_data, on=\"location\", how=\"left\")\n",
        "\n",
        "# 7. Check for Missing Coordinates\n",
        "merged_data = merged_data.dropna(subset=['latitude', 'longitude'])\n",
        "\n",
        "# 8. Plot Map\n",
        "if not merged_data.empty:\n",
        "    st.header(\"Map Visualization of Locations\")\n",
        "    fig = px.scatter_mapbox(\n",
        "        merged_data,\n",
        "        lat=\"latitude\",\n",
        "        lon=\"longitude\",\n",
        "        hover_name=\"location\",\n",
        "        zoom=8,\n",
        "        height=600,\n",
        "        title=\"Map Visualization of Selected Property Type\"\n",
        "    )\n",
        "    fig.update_layout(mapbox_style=\"open-street-map\")\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "else:\n",
        "    st.warning(\"No valid locations found for mapping.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpZxQOAwn59O",
        "outputId": "480c18fa-0575-4a42-bebd-137d41405cd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting visual.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile dashboard.py\n",
        "import streamlit as st\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import pickle\n",
        "\n",
        "st.title(\"Rent Pricing at Kuala Lumpur and Selangor\")\n",
        "\n",
        "# Load dataset dynamically\n",
        "# Replace 'your_dataset.csv' with the actual file path to your dataset\n",
        "@st.cache_data\n",
        "def load_data():\n",
        "    df = pd.read_csv('/content/drive/MyDrive/FYP B IZZA/mudah-apartment-kl-selangor_cleaned.csv')  # Replace with your dataset file\n",
        "    # Normalize column names\n",
        "    df.columns = df.columns.str.strip().str.lower()\n",
        "\n",
        "    # Clean 'monthly_rent' column (removes RM, per month, and spaces)\n",
        "    df['monthly_rent'] = (\n",
        "        df['monthly_rent']\n",
        "        .str.replace('RM', '', regex=False)           # Remove RM\n",
        "        .str.replace('per month', '', regex=False)    # Remove 'per month'\n",
        "        .str.replace(' ', '', regex=False)            # Remove spaces between numbers\n",
        "        .apply(pd.to_numeric, errors='coerce')         # Convert to float, coerce errors to NaN\n",
        "    )\n",
        "\n",
        "    # Ensure numeric columns are properly converted to numeric, coercing errors to NaN\n",
        "    numeric_columns = ['rooms', 'bathroom', 'parking']\n",
        "    for col in numeric_columns:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')  # Use pd.to_numeric to handle non-numeric values\n",
        "\n",
        "    # Drop rows with NaN values in numeric columns if necessary (e.g., for prediction)\n",
        "    df = df.dropna(subset=numeric_columns + ['monthly_rent'])\n",
        "\n",
        "    return df\n",
        "\n",
        "df = load_data()\n",
        "\n",
        "# Check if required columns exist\n",
        "required_columns = ['location', 'property_type', 'rooms', 'bathroom', 'parking', 'monthly_rent']\n",
        "if not all(col in df.columns for col in required_columns):\n",
        "    st.error(f\"The dataset must contain the following columns: {required_columns}\")\n",
        "    st.stop()\n",
        "\n",
        "# Convert 'monthly_rent' column to numeric, forcing errors to NaN (invalid data will be excluded)\n",
        "df['monthly_rent'] = pd.to_numeric(df['monthly_rent'], errors='coerce')\n",
        "\n",
        "# Sidebar for user input (only for graph parameters)\n",
        "st.sidebar.title('Interactive Graphs')\n",
        "st.sidebar.header('Graph Parameters')\n",
        "\n",
        "# User selects the parameters for filtering data\n",
        "selected_locations = st.sidebar.multiselect('Select Locations', df['location'].unique())\n",
        "selected_property_types = st.sidebar.multiselect('Select Property Types', df['property_type'].unique())\n",
        "\n",
        "# Filter dataset based on user selection\n",
        "filtered_data = df[\n",
        "    (df['location'].isin(selected_locations)) &\n",
        "    (df['property_type'].isin(selected_property_types))\n",
        "]\n",
        "\n",
        "# Check if the filtered data is empty\n",
        "if filtered_data.empty:\n",
        "    st.warning(\"No data available for the selected filters.\")\n",
        "else:\n",
        "    # Visualization Columns\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    # Graph 1: Average Price by Location\n",
        "    avg_price_location = filtered_data.groupby('location')['monthly_rent'].mean().reset_index()\n",
        "    avg_price_location['monthly_rent'] = avg_price_location['monthly_rent'].round(2)  # Round to 2 decimal places\n",
        "    fig1 = px.bar(avg_price_location, x='location', y='monthly_rent', color='location', title=\"Average Price by Location\")\n",
        "    col1.plotly_chart(fig1, use_container_width=True)\n",
        "\n",
        "    # Graph 2: Average Price by Property Type\n",
        "    avg_price_property = filtered_data.groupby('property_type')['monthly_rent'].mean().reset_index()\n",
        "    avg_price_property['monthly_rent'] = avg_price_property['monthly_rent'].round(2)  # Round to 2 decimal places\n",
        "    fig2 = px.bar(avg_price_property, x='property_type', y='monthly_rent', color='property_type', title=\"Average Price by Property Type\")\n",
        "    col2.plotly_chart(fig2, use_container_width=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ht4L0GJR8mkS",
        "outputId": "42ce654d-77df-42e0-c4d9-37d7349a306d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting dashboard.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile dashboard.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import pickle\n",
        "\n",
        "st.title(\"Rent Pricing at Kuala Lumpur and Selangor\")\n",
        "\n",
        "# Load and preprocess dataset\n",
        "@st.cache_data\n",
        "def load_data():\n",
        "    df = pd.read_csv('/content/drive/MyDrive/FYP B IZZA/mudah-apartment-kl-selangor_cleaned.csv')  # Replace with your dataset file\n",
        "    # Normalize column names\n",
        "    df.columns = df.columns.str.strip().str.lower()\n",
        "\n",
        "    # Clean 'monthly_rent' column (removes RM, per month, and spaces)\n",
        "    df['monthly_rent'] = (\n",
        "        df['monthly_rent']\n",
        "        .str.replace('RM', '', regex=False)           # Remove RM\n",
        "        .str.replace('per month', '', regex=False)    # Remove 'per month'\n",
        "        .str.replace(' ', '', regex=False)            # Remove spaces between numbers\n",
        "        .apply(pd.to_numeric, errors='coerce')         # Convert to float, coerce errors to NaN\n",
        "    )\n",
        "\n",
        "    # Ensure numeric columns are properly converted to numeric, coercing errors to NaN\n",
        "    numeric_columns = ['rooms', 'bathroom', 'parking']\n",
        "    for col in numeric_columns:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')  # Use pd.to_numeric to handle non-numeric values\n",
        "\n",
        "    # Drop rows with NaN values in numeric columns if necessary (e.g., for prediction)\n",
        "    df = df.dropna(subset=numeric_columns + ['monthly_rent'])\n",
        "\n",
        "    return df\n",
        "\n",
        "df = load_data()\n",
        "\n",
        "# Check if required columns exist\n",
        "required_columns = ['location', 'property_type', 'rooms', 'bathroom', 'parking', 'monthly_rent']\n",
        "if not all(col in df.columns for col in required_columns):\n",
        "    st.error(f\"The dataset must contain the following columns: {required_columns}\")\n",
        "    st.stop()\n",
        "\n",
        "# Load trained model\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    with open('/content/drive/MyDrive/FYP B IZZA/best_model_pipeline.pkl', 'rb') as f:\n",
        "        model = pickle.load(f)\n",
        "    return model\n",
        "\n",
        "model = load_model()\n",
        "\n",
        "# Sidebar for user input\n",
        "st.sidebar.title('Input Parameters for Prediction')\n",
        "st.sidebar.header('Prediction Inputs')\n",
        "\n",
        "# Dynamically populate dropdowns and sliders\n",
        "location = st.sidebar.selectbox('Select Location', df['location'].unique())\n",
        "property_type = st.sidebar.selectbox('Select Property Type', df['property_type'].unique())\n",
        "bedrooms = st.sidebar.slider('Number of Bedrooms', min_value=int(df['rooms'].min()), max_value=int(df['rooms'].max()), step=1)\n",
        "bathrooms = st.sidebar.slider('Number of Bathrooms', min_value=int(df['bathroom'].min()), max_value=int(df['bathroom'].max()), step=1)\n",
        "parking = st.sidebar.slider('Number of Parking Spaces', min_value=int(df['parking'].min()), max_value=int(df['parking'].max()), step=1)\n",
        "\n",
        "# Prepare input data for prediction\n",
        "input_data = pd.DataFrame({\n",
        "    'location': [location],\n",
        "    'property_type': [property_type],\n",
        "    'rooms': [bedrooms],\n",
        "    'bathroom': [bathrooms],\n",
        "    'parking': [parking],\n",
        "})\n",
        "\n",
        "# Prediction button\n",
        "if st.sidebar.button('Predict'):\n",
        "    try:\n",
        "        prediction = model.predict(input_data)\n",
        "        st.sidebar.success(f\"Predicted Rent: RM{prediction[0]:,.2f}\")\n",
        "    except Exception as e:\n",
        "        st.sidebar.error(f\"Prediction failed: {e}\")\n",
        "\n",
        "# Interactive Graphs Section\n",
        "st.header(\"Interactive Graphs\")\n",
        "st.sidebar.header('Graph Parameters')\n",
        "\n",
        "# Filter dataset based on user selection\n",
        "selected_locations = st.sidebar.multiselect('Select Locations', df['location'].unique(), default=df['location'].unique())\n",
        "selected_property_types = st.sidebar.multiselect('Select Property Types', df['property_type'].unique(), default=df['property_type'].unique())\n",
        "\n",
        "filtered_data = df[\n",
        "    (df['location'].isin(selected_locations)) &\n",
        "    (df['property_type'].isin(selected_property_types))\n",
        "]\n",
        "\n",
        "# Visualization Columns\n",
        "col1, col2 = st.columns(2)\n",
        "\n",
        "# Graph 1: Average Price by Location\n",
        "if not filtered_data.empty:\n",
        "    avg_price_location = filtered_data.groupby('location')['monthly_rent'].mean().reset_index()\n",
        "    fig1 = px.bar(avg_price_location, x='location', y='monthly_rent', color='location', title=\"Average Price by Location\")\n",
        "    col1.plotly_chart(fig1, use_container_width=True)\n",
        "\n",
        "# Graph 2: Average Price by Property Type\n",
        "if not filtered_data.empty:\n",
        "    avg_price_property = filtered_data.groupby('property_type')['monthly_rent'].mean().reset_index()\n",
        "    fig2 = px.bar(avg_price_property, x='property_type', y='monthly_rent', color='property_type', title=\"Average Price by Property Type\")\n",
        "    col2.plotly_chart(fig2, use_container_width=True)\n",
        "\n",
        "# Scatter plots for additional insights\n",
        "col3, col4 = st.columns(2)\n",
        "if not filtered_data.empty:\n",
        "    fig3 = px.scatter(filtered_data, x='rooms', y='monthly_rent', color='location', title=\"Bedrooms vs. Rent\")\n",
        "    col3.plotly_chart(fig3, use_container_width=True)\n",
        "\n",
        "    fig4 = px.scatter(filtered_data, x='bathroom', y='monthly_rent', color='location', title=\"Bathrooms vs. Rent\")\n",
        "    col4.plotly_chart(fig4, use_container_width=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zUYs94eQ8IO",
        "outputId": "b9c6efd3-626d-4468-808e-65ec3f30c4b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting dashboard.py\n"
          ]
        }
      ]
    }
  ]
}